(window.webpackJsonp_N_E=window.webpackJsonp_N_E||[]).push([[23],{MWOg:function(e,n,t){"use strict";t.r(n),function(e,r){var a=t("o0o1"),i=t.n(a),o=t("HaE+"),s=t("8i9l"),c=t("nBne"),l=t("OI48"),u=function(){var e=Object(o.a)(i.a.mark((function e(n){var t,r,a,o,s,u,d,m,p,g,f;return i.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return f=function(){if(t.current){var e=a.createCommandEncoder(),n={colorAttachments:[{view:g,resolveTarget:o.getCurrentTexture().createView(),clearValue:{r:0,g:0,b:0,a:1},loadOp:"clear",storeOp:"discard"}]},r=e.beginRenderPass(n);r.setPipeline(m),r.draw(3,1,0,0),r.end(),a.queue.submit([e.finish()]),requestAnimationFrame(f)}},t=n.canvasRef,e.next=4,navigator.gpu.requestAdapter();case 4:return r=e.sent,e.next=7,r.requestDevice();case 7:if(a=e.sent,null!==t.current){e.next=10;break}return e.abrupt("return");case 10:o=t.current.getContext("webgpu"),s=window.devicePixelRatio||1,u=[t.current.clientWidth*s,t.current.clientHeight*s],d=navigator.gpu.getPreferredCanvasFormat(),o.configure({device:a,size:u,format:d,alphaMode:"opaque"}),4,m=a.createRenderPipeline({layout:"auto",vertex:{module:a.createShaderModule({code:c.a}),entryPoint:"main"},fragment:{module:a.createShaderModule({code:l.a}),entryPoint:"main",targets:[{format:d}]},primitive:{topology:"triangle-list"},multisample:{count:4}}),p=a.createTexture({size:u,sampleCount:4,format:d,usage:GPUTextureUsage.RENDER_ATTACHMENT}),g=p.createView(),requestAnimationFrame(f);case 20:case"end":return e.stop()}}),e)})));return function(n){return e.apply(this,arguments)}}();n.default=function(){return Object(s.a)({name:"Hello Triangle MSAA",description:"Shows multisampled rendering a basic triangle.",init:u,sources:[{name:e.substring(r.length+1),contents:"import { makeSample, SampleInit } from '../../components/SampleLayout';\n\nimport triangleVertWGSL from '../../shaders/triangle.vert.wgsl';\nimport redFragWGSL from '../../shaders/red.frag.wgsl';\n\nconst init: SampleInit = async ({ canvasRef }) => {\n  const adapter = await navigator.gpu.requestAdapter();\n  const device = await adapter.requestDevice();\n\n  if (canvasRef.current === null) return;\n  const context = canvasRef.current.getContext('webgpu') as GPUCanvasContext;\n\n  const devicePixelRatio = window.devicePixelRatio || 1;\n  const presentationSize = [\n    canvasRef.current.clientWidth * devicePixelRatio,\n    canvasRef.current.clientHeight * devicePixelRatio,\n  ];\n  const presentationFormat = navigator.gpu.getPreferredCanvasFormat();\n\n  context.configure({\n    device,\n    size: presentationSize,\n    format: presentationFormat,\n    alphaMode: 'opaque',\n  });\n\n  const sampleCount = 4;\n\n  const pipeline = device.createRenderPipeline({\n    layout: 'auto',\n    vertex: {\n      module: device.createShaderModule({\n        code: triangleVertWGSL,\n      }),\n      entryPoint: 'main',\n    },\n    fragment: {\n      module: device.createShaderModule({\n        code: redFragWGSL,\n      }),\n      entryPoint: 'main',\n      targets: [\n        {\n          format: presentationFormat,\n        },\n      ],\n    },\n    primitive: {\n      topology: 'triangle-list',\n    },\n    multisample: {\n      count: 4,\n    },\n  });\n\n  const texture = device.createTexture({\n    size: presentationSize,\n    sampleCount,\n    format: presentationFormat,\n    usage: GPUTextureUsage.RENDER_ATTACHMENT,\n  });\n  const view = texture.createView();\n\n  function frame() {\n    // Sample is no longer the active page.\n    if (!canvasRef.current) return;\n\n    const commandEncoder = device.createCommandEncoder();\n\n    const renderPassDescriptor: GPURenderPassDescriptor = {\n      colorAttachments: [\n        {\n          view,\n          resolveTarget: context.getCurrentTexture().createView(),\n          clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },\n          loadOp: 'clear',\n          storeOp: 'discard',\n        },\n      ],\n    };\n\n    const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);\n    passEncoder.setPipeline(pipeline);\n    passEncoder.draw(3, 1, 0, 0);\n    passEncoder.end();\n\n    device.queue.submit([commandEncoder.finish()]);\n    requestAnimationFrame(frame);\n  }\n\n  requestAnimationFrame(frame);\n};\n\nconst HelloTriangleMSAA: () => JSX.Element = () =>\n  makeSample({\n    name: 'Hello Triangle MSAA',\n    description: 'Shows multisampled rendering a basic triangle.',\n    init,\n    sources: [\n      {\n        name: __filename.substring(__dirname.length + 1),\n        contents: __SOURCE__,\n      },\n      {\n        name: '../../shaders/triangle.vert.wgsl',\n        contents: triangleVertWGSL,\n        editable: true,\n      },\n      {\n        name: '../../shaders/red.frag.wgsl',\n        contents: redFragWGSL,\n        editable: true,\n      },\n    ],\n    filename: __filename,\n  });\n\nexport default HelloTriangleMSAA;\n"},{name:"../../shaders/triangle.vert.wgsl",contents:c.a,editable:!0},{name:"../../shaders/red.frag.wgsl",contents:l.a,editable:!0}],filename:e})}}.call(this,"src/sample/helloTriangleMSAA/main.ts","src/sample/helloTriangleMSAA")},OI48:function(e,n,t){"use strict";n.a="@fragment\nfn main() -> @location(0) vec4<f32> {\n  return vec4<f32>(1.0, 0.0, 0.0, 1.0);\n}"},nBne:function(e,n,t){"use strict";n.a="@vertex\nfn main(\n  @builtin(vertex_index) VertexIndex : u32\n) -> @builtin(position) vec4<f32> {\n  var pos = array<vec2<f32>, 3>(\n    vec2<f32>(0.0, 0.5),\n    vec2<f32>(-0.5, -0.5),\n    vec2<f32>(0.5, -0.5)\n  );\n\n  return vec4<f32>(pos[VertexIndex], 0.0, 1.0);\n}\n"}}]);